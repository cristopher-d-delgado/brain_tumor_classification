{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://localhost:5000/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x24d2a9541c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://localhost:5000/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x24d276007f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import jupyter notebook version of dash framework\n",
    "from jupyter_dash import JupyterDash as Dash\n",
    "# import dash components\n",
    "from dash import Input, Output, State, html, dcc\n",
    "# Import warnings to ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import base64\n",
    "# import load_model from keras\n",
    "import tensorflow as tf\n",
    "# Import visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.segmentation import mark_boundaries\n",
    "# Import Explainer \n",
    "from lime import lime_image\n",
    "\n",
    "# For now we will load it locally\n",
    "model = tf.keras.models.load_model(\"../models/op_model1_aug.keras\")\n",
    "\n",
    "# Define style sheet \n",
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "\n",
    "# Create the dash app\n",
    "app = Dash(__name__, external_stylesheets=external_stylesheets)\n",
    "\n",
    "# Create markdown for our dashboard\n",
    "markdown_1 = html.Div(dcc.Markdown(\"\"\"\n",
    "    # Brain Tumor Lesion Assesment\n",
    "\"\"\"))\n",
    "\n",
    "markdown_2 = html.Div(dcc.Markdown(\"\"\"\n",
    "    The model integrated in into this dashbaord has the capability to predict different brian lesions.\n",
    "    The four supported brain lession classification are Meningioma, Pituitary, Glioma tumors. \n",
    "    The fourth possible prediction would be a No Tumor classification.\n",
    "\"\"\"))\n",
    "\n",
    "# Upload image\n",
    "upload_img = dcc.Upload(\n",
    "    id='upload-image',\n",
    "    children=html.Div([\n",
    "        'Drag and Drop or ',\n",
    "        html.A('Select File')\n",
    "    ]),\n",
    "        style={\n",
    "        'width': '100%',\n",
    "        'height': '60px',\n",
    "        'lineHeight': '60px',\n",
    "        'borderWidth': '1px',\n",
    "        'borderStyle': 'dashed',\n",
    "        'borderRadius': '5px',\n",
    "        'textAlign': 'center',\n",
    "        'margin': '10px'\n",
    "    },\n",
    "    multiple=True, # Do not allow multiple uploads\n",
    ")\n",
    "\n",
    "# Define the output component\n",
    "prediction_output = html.Div(id='prediction-output')\n",
    "lime_mask_img = html.Div(id='lime-mask-container')\n",
    "lime_heatmap_img = html.Div(id='heatmap-container')\n",
    "\n",
    "# Set the layout\n",
    "app.layout = html.Div(children=[\n",
    "    markdown_1,\n",
    "    markdown_2,\n",
    "    html.Div([upload_img, html.Div(id='output-image-upload')]), # Upload image and update image\n",
    "    prediction_output,\n",
    "    lime_mask_img, # Display Lime Mask\n",
    "    lime_heatmap_img, # Display Importance Heatmap\n",
    "])\n",
    "\n",
    "\n",
    "############################################################################################################################\n",
    "# function to parse file path \n",
    "def parse_contents(contents, filename):\n",
    "    return html.Div([\n",
    "        html.H5(filename),\n",
    "\n",
    "        # HTML images accept base64 encoded strings in the same format\n",
    "        # that is supplied by the upload\n",
    "        html.Img(src=contents),\n",
    "        html.Hr()\n",
    "    ])\n",
    "# Define callback to change image upload\n",
    "@app.callback(\n",
    "    Output('output-image-upload', 'children'),\n",
    "    Input('upload-image', 'contents'),\n",
    "    State('upload-image', 'filename')\n",
    ")\n",
    "# Define an update function for the uploaded image\n",
    "def update_output(list_of_contents, list_of_names):\n",
    "    if list_of_contents is not None:\n",
    "        children = [\n",
    "            parse_contents(c, n) for c, n in\n",
    "            zip(list_of_contents, list_of_names)]\n",
    "        return children \n",
    "\n",
    "\n",
    "# Define a function to generate Lime explanations\n",
    "def generate_lime_explanation(image_bytes):\n",
    "    if image_bytes is not None:\n",
    "        # Load the Lime explainer\n",
    "        explainer = lime_image.LimeImageExplainer(random_state=42)\n",
    "        \n",
    "        # Preprocess the image for Lime explanation and model prediction\n",
    "        decoded_image = base64.b64decode(image_bytes.split(\",\")[1])\n",
    "        img = Image.open(BytesIO(decoded_image))\n",
    "        img = img.convert('RGB') # Convert image to RGB\n",
    "        img = img.resize((128, 128)) # Resize the image to expected model image dimensions  \n",
    "        img = np.array(img) / 255.0  # Normalize the image\n",
    "        \n",
    "        # Develop local model explanation\n",
    "        explanation = explainer.explain_instance(\n",
    "            image=img,\n",
    "            classifier_fn=model.predict,\n",
    "            top_labels=4,\n",
    "            num_samples=2000,\n",
    "            hide_color=0,\n",
    "            random_seed=42\n",
    "        )\n",
    "        \n",
    "        return explanation\n",
    "\n",
    "# Define a function to display Lime explanations\n",
    "def display_lime_explanation(explanation):\n",
    "    # Obtain mask and image from the explainer\n",
    "    temp, mask = explanation.get_image_and_mask(\n",
    "        explanation.top_labels[0],  # Using the top predicted label for visualization\n",
    "        positive_only=True,\n",
    "        num_features=5,\n",
    "        hide_rest=True,\n",
    "        min_weight=0.1\n",
    "    )\n",
    "    \n",
    "    # Display the Lime Mask\n",
    "    plt.figure(figsize=(8, 6), facecolor='white')\n",
    "    plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))\n",
    "    plt.title(\"Concerning Area\", fontsize=20)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the Lime Mask Plot as bytes\n",
    "    mask_buf = BytesIO()\n",
    "    plt.savefig(mask_buf, format='png')\n",
    "    mask_buf.seek(0)\n",
    "    mask_bytes64 = base64.b64encode(mask_buf.read()).decode()\n",
    "    plt.close()\n",
    "    \n",
    "    # Obtain heatmap version that explains the areas that contribute most to that decision\n",
    "    ind = explanation.top_labels[0]\n",
    "    dict_heatmap = dict(explanation.local_exp[ind])\n",
    "    heatmap = np.vectorize(dict_heatmap.get)(explanation.segments)\n",
    "    \n",
    "    # Display the heatmap\n",
    "    plt.figure(figsize=(8, 6), facecolor='white')\n",
    "    plt.imshow(heatmap, cmap='RdBu', vmin=-heatmap.max(), vmax=heatmap.max())\n",
    "    plt.title(\"Blue = More Important; Red = Less Important\", fontsize=20)\n",
    "    plt.axis(\"off\")  # Hide axes\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the Heatmap plot as bytes\n",
    "    heatmap_buf = BytesIO()\n",
    "    plt.savefig(heatmap_buf, format='png')\n",
    "    heatmap_buf.seek(0)\n",
    "    heatmap_bytes64 = base64.b64encode(heatmap_buf.read()).decode()\n",
    "    plt.close()\n",
    "    \n",
    "    return mask_bytes64, heatmap_bytes64\n",
    "\n",
    "# Define the callback to preprocess the image and make predictions\n",
    "@app.callback(\n",
    "    [Output('prediction-output', 'children'),\n",
    "    Output('lime-mask-container', 'children'),\n",
    "    Output('heatmap-container', 'children')],\n",
    "    [Input('upload-image', 'contents')]\n",
    ")\n",
    "\n",
    "def update_prediction_output(contents):\n",
    "    if contents is not None:\n",
    "        max_prediction_label = None\n",
    "        max_prediction_value = 0\n",
    "        lime_mask_images = []\n",
    "        heatmap_images = []\n",
    "        \n",
    "        for content in contents:\n",
    "            content_type, content_string = content.split(',')\n",
    "            \n",
    "            # Decode the uploaded image\n",
    "            decoded_image = base64.b64decode(content_string)\n",
    "            \n",
    "            # Preprocess the image\n",
    "            img = Image.open(BytesIO(decoded_image))\n",
    "            img = img.convert('RGB') # Convert image to RGB\n",
    "            img = img.resize((128, 128)) # Resize the image to expected model image dimensions  \n",
    "            img = np.array(img) / 255.0  # Normalize the image\n",
    "            \n",
    "            # Make prediction\n",
    "            prediction = model.predict(np.expand_dims(img, axis=0))\n",
    "            \n",
    "            # Get the index of the class with the highest probability\n",
    "            max_index = np.argmax(prediction)\n",
    "            \n",
    "            # Map the index to the corresponding class label\n",
    "            if max_index == 0:\n",
    "                max_prediction_label = 'glioma'\n",
    "            elif max_index == 1:\n",
    "                max_prediction_label = 'meningioma'\n",
    "            elif max_index == 2:\n",
    "                max_prediction_label = 'no_tumor'\n",
    "            elif max_index == 3:\n",
    "                max_prediction_label = 'pituitary'\n",
    "            \n",
    "            # If the max probability for this image is higher, update the label\n",
    "            if prediction[0, max_index] > max_prediction_value:\n",
    "                max_prediction_value = prediction[0, max_index]\n",
    "                \n",
    "            # Generate Lime explanation\n",
    "            explanation = generate_lime_explanation(content_string)\n",
    "                \n",
    "            # Get Lime bytes for image_mask and heatmap  \n",
    "            lime_mask_bytes, heatmap_bytes = display_lime_explanation(explanation)\n",
    "            lime_mask_images.append('data:image/png;base64,' + lime_mask_bytes)\n",
    "            heatmap_images.append('data:image/png;base64,' + heatmap_bytes)\n",
    "            \n",
    "        # Return label with highest probablity \n",
    "        if max_prediction_label:\n",
    "            return f\"Prediction: {max_prediction_label.capitalize()}\", lime_mask_images, heatmap_images\n",
    "        else:\n",
    "            return \"No prediction available\", [], []\n",
    "\n",
    "##############################################################################################################################\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(mode='inline', host='localhost', port=5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpudl3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
