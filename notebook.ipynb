{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain Tumor Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data managing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import Tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "# Set the seed for repeatability\n",
    "seed = 42\n",
    "\n",
    "# Set random seed for NumPy\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set random seed for TensorFlow\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Set random seed for Python's built-in random module\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import process_data\n",
    "import os\n",
    "\n",
    "# Define data folder\n",
    "data_folder = \"data/\"\n",
    "\n",
    "# Define train, val, test folders\n",
    "train_folder = os.path.join(data_folder, \"Training/\")\n",
    "test_folder = os.path.join(data_folder, \"Testing/\")\n",
    "val_folder = os.path.join(data_folder, \"Validation/\")\n",
    "\n",
    "# Define our data directories\n",
    "train_data_dir = train_folder\n",
    "test_data_dir = test_folder\n",
    "val_data_dir = val_folder\n",
    "\n",
    "train_generator, test_generator, validation_generator = process_data(256, 32, train_data_dir, test_data_dir, val_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutinal Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "# Define metrics we want to log for the compile method callback\n",
    "metrics = [\n",
    "        Precision(name='precision'),\n",
    "        Recall(name='recall'),\n",
    "        'accuracy'\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "# Define input shape\n",
    "input_shape = (128, 128, 3)\n",
    "\n",
    "# Define the basic model \n",
    "model_mlp_base = Sequential()\n",
    "\n",
    "# Define the layers \n",
    "# Flatten layer to reshape the output\n",
    "model_mlp_base.add(Flatten(input_shape=input_shape))\n",
    "model_mlp_base.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Define the output \n",
    "model_mlp_base.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model_mlp_base.compile(optimizer=Adam(), loss=BinaryCrossentropy(), metrics=METRICS)\n",
    "print(model_mlp_base.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpudl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
